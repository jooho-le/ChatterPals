import json
import os
import io
import asyncio
import subprocess
import shutil
from pathlib import Path
import traceback
from typing import Literal

from fastapi import FastAPI, HTTPException, Query, Response, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
from dotenv import load_dotenv, find_dotenv
import google.generativeai as genai
import requests

# --- í™˜ê²½ ë³€ìˆ˜ ë° API í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ---
load_dotenv(find_dotenv())
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    raise RuntimeError("'.env' íŒŒì¼ì— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
genai.configure(api_key=GOOGLE_API_KEY)

ELEVEN_API_KEY = os.getenv("ELEVEN_API_KEY")
if not ELEVEN_API_KEY:
    raise RuntimeError("'.env' íŒŒì¼ì— ELEVEN_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")

# --- FastAPI ì•± ì´ˆê¸°í™” ---
app = FastAPI(title="ChatterPals Voice API", version="1.2.1")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ëª¨ë¸ ë° í”„ë¡¬í”„íŠ¸ ì„¤ì • ---
MODEL_STT = "gemini-2.0-flash-lite-preview"
MODEL_CHAT = "gemini-2.0-flash-lite-preview"
SYSTEM_PROMPT = "ë„ˆëŠ” ì¹œì ˆí•˜ê³  ìƒëƒ¥í•œ AI ì™¸êµ­ì–´ êµìœ¡ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ë°œìŒ,íšŒí™”, ë¬¸ë²•ë“±ì„ ëŒ€í™”í•˜ë©´ì„œ ë„ì™€ì£¼ëŠ” ì„ ìƒë‹˜ì´ì§€."

# --- í—¬í¼ í•¨ìˆ˜ ---
SUPPORTED_DIRECT_MIME = {
    "audio/wav",
    "audio/x-wav",
    "audio/vnd.wave",
    "audio/wave",
}


class TextRequest(BaseModel):
    text: str


class HintRequest(BaseModel):
    context: str
    level: Literal["starter", "keywords", "translation"]
    usage_count: int = 0


class HintResponse(BaseModel):
    level: Literal["starter", "keywords", "translation"]
    hint_text: str
    keywords: list[str] | None = None
    playful_remark: str | None = None


class AnswerCheckRequest(BaseModel):
    question: str
    user_answer: str
    context: str | None = None


class AnswerCheckResponse(BaseModel):
    is_correct: bool
    feedback: str
    score: float | None = None
    model_answer: str | None = None

def transcode_to_wav_pcm16k(audio_bytes: bytes, mime_type: str | None = None) -> bytes:
    ffmpeg_path = shutil.which("ffmpeg")
    if not ffmpeg_path:
        if mime_type and mime_type in SUPPORTED_DIRECT_MIME:
            return audio_bytes
        raise FileNotFoundError("FFmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì— FFmpegë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

    base_command = [
        ffmpeg_path, '-i', 'pipe:0', '-acodec', 'pcm_s16le',
        '-ar', '16000', '-ac', '1', '-f', 'wav', 'pipe:1'
    ]

    command = base_command.copy()
    if mime_type and mime_type in {"audio/pcm", "application/octet-stream"}:
        command = [
            ffmpeg_path, '-f', 's16le', '-ar', '44100', '-ac', '1', '-i', 'pipe:0',
            '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', '-f', 'wav', 'pipe:1'
        ]

    try:
        process = subprocess.run(command, input=audio_bytes, capture_output=True, check=True)
    except subprocess.CalledProcessError as error:
        if mime_type and mime_type in SUPPORTED_DIRECT_MIME:
            return audio_bytes
        raise error

    return process.stdout

async def stream_text_to_speech_bytes(text: str):
    voice_id = "EXAVITQu4vr4xnSDxMaL"
    url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream"
    headers = {"xi-api-key": ELEVEN_API_KEY, "Content-Type": "application/json"}
    payload = {
        "text": text, "model_id": "eleven_multilingual_v2",
        "voice_settings": {"stability": 0.5, "similarity_boost": 0.75}
    }
    try:
        response = requests.post(url, headers=headers, json=payload, stream=True)
        response.raise_for_status()
        for chunk in response.iter_content(chunk_size=1024):
            if chunk: yield chunk
    except Exception as e:
        print(f"TTS ì˜¤ë¥˜: {e}")
        yield b''

# --- API ì—”ë“œí¬ì¸íŠ¸ ---
@app.get("/")
def get_status():
    return {"status": "Voice server is running"}

@app.post("/api/get-ai-response")
async def get_ai_response(audio: UploadFile = File(...)):
    try:
        print("[1/3] ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜ì‹  ë° ë³€í™˜ ì¤‘...")
        input_audio_bytes = await audio.read()
        wav_audio_bytes = transcode_to_wav_pcm16k(input_audio_bytes, audio.content_type)

        print("[2/3] Gemini File APIì— ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ë° STT ì‹¤í–‰ ì¤‘...")
        uploaded_file = genai.upload_file(
            path=io.BytesIO(wav_audio_bytes),
            display_name="user_audio.wav",
            mime_type="audio/wav"
        )
        stt_model = genai.GenerativeModel(MODEL_STT)

        # AIê°€ ë” ì˜ ì¸ì‹í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ìˆ˜ì •
        stt_prompt = "ì´ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë°›ì•„ì ì–´ ì£¼ì„¸ìš”."
        stt_response = await stt_model.generate_content_async([stt_prompt, uploaded_file])
        
        # ë” ì•ˆì •ì ì¸ íŒŒì‹± ë°©ë²• ì‚¬ìš©
        transcript = "".join(part.text for part in stt_response.candidates[0].content.parts).strip()
        print(f"[2/3] STT ê²°ê³¼: '{transcript}'")

        # 'ì¸ì‹ ì‹¤íŒ¨' ë¬¸ìì—´ ëŒ€ì‹ , ê²°ê³¼ê°€ ë¹„ì–´ ìˆëŠ”ì§€ ì—¬ë¶€ë¡œ íŒë‹¨
        if not transcript:
            print("[ì˜¤ë¥˜] STT ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìŒì„± ì¸ì‹ì´ ì‹¤íŒ¨í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.")
            raise ValueError("STT recognized empty text.")

        print("[3/3] Gemini ì±„íŒ… ì‘ë‹µ ìƒì„± ì¤‘...")
        chat_model = genai.GenerativeModel(MODEL_CHAT, system_instruction=SYSTEM_PROMPT)
        llm_response = await chat_model.generate_content_async(transcript)
        response_text = "".join(part.text for part in llm_response.candidates[0].content.parts).strip()
        print(f"[3/3] Gemini ì‘ë‹µ: {response_text}")

        return JSONResponse(content={"transcript": transcript, "response_text": response_text})

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ìŒì„± ì²˜ë¦¬ ì¤‘ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.post("/api/get-ai-response-from-text")
async def get_ai_response_from_text(payload: TextRequest):
    transcript = payload.text.strip()
    if not transcript:
        raise HTTPException(status_code=400, detail="ì§ˆë¬¸ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    try:
        chat_model = genai.GenerativeModel(MODEL_CHAT, system_instruction=SYSTEM_PROMPT)
        llm_response = await chat_model.generate_content_async(transcript)
        response_text = "".join(
            part.text for part in llm_response.candidates[0].content.parts
        ).strip()
        if not response_text:
            raise ValueError("ìƒì„±ëœ ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return {"transcript": transcript, "response_text": response_text}
    except Exception as error:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"í…ìŠ¤íŠ¸ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {error}")


@app.get("/api/tts")
async def tts_streaming_endpoint(text: str = Query(..., min_length=1)):
    return StreamingResponse(stream_text_to_speech_bytes(text), media_type="audio/mpeg")


HINT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì˜ì–´ íšŒí™”ì™€ ë…í•´ í•™ìŠµì„ ë•ëŠ” ì¥ë‚œê¾¸ëŸ¬ê¸° íŠœí„°ì…ë‹ˆë‹¤.
ì •ë‹µì„ ì§ì ‘ ë§í•˜ì§€ ì•Šê³ , í•™ìŠµìê°€ ìŠ¤ìŠ¤ë¡œ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ” ë¶€ë“œëŸ¬ìš´ ë‹¨ì„œë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ëª¨ë“  ì‘ë‹µì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë˜, í•„ìš”í•œ ì˜ì–´ ë‹¨ì–´ëŠ” ê´„í˜¸ ì•ˆì— ë³‘ê¸°í•˜ì„¸ìš”."""

EVAL_SYSTEM_PROMPT = """You are an English language tutor grading short answers.
Always respond with JSON only and be fair and concise in your evaluation."""

HINT_LEVEL_TEMPLATES = {
    "starter": """[Role] Provide one or two short hints in ENGLISH that help the learner guess the missing expression without giving the exact answer.
- Speak only in English.
- Encourage the learner to think about the meaning or nuance.

[Context]
{context}

[Output]
1-2 friendly English hint sentences.""",
    "keywords": """[ì—­í• ] ì •ë‹µì„ ë– ì˜¬ë¦¬ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í•œêµ­ì–´ í•µì‹¬ ë‹¨ì–´ 3ê°œë¥¼ ê³¨ë¼.
- í‚¤ì›Œë“œëŠ” í•œêµ­ì–´ 1~3ì–´ì ˆë¡œ ì œì‹œí•´.
- ì˜ì–´ ë²ˆì—­ì€ ì ì§€ ì•Šì•„.

[ë¬¸ë§¥]
{context}

[ì¶œë ¥]
- ë‹¨ì–´1
- ë‹¨ì–´2
- ë‹¨ì–´3""",
    "translation": """[ì—­í• ] í•™ìŠµìê°€ ë°©í–¥ì„ ì¡ì„ ìˆ˜ ìˆë„ë¡ ë¬¸ë§¥ì˜ ì¼ë¶€ë§Œ í•œêµ­ì–´ë¡œ ì‚´ì§ ë²ˆì—­í•´.
- 40ì ì´ë‚´ì˜ ì§§ì€ í•œêµ­ì–´ ë¬¸ì¥ 1ê°œë§Œ ì œê³µ.
- ì „ì²´ ì •ë‹µì„ ì•Œ ìˆ˜ëŠ” ì—†ì§€ë§Œ ê°ì„ ì¡ì„ ìˆ˜ ìˆê²Œ í•´.

[ë¬¸ë§¥]
{context}

[ì¶œë ¥]
ì§§ì€ í•œêµ­ì–´ ë¬¸ì¥ 1ê°œ.""",
}


def _extract_keywords(raw_text: str) -> list[str]:
    normalized = raw_text.replace("â€¢", "\n").replace(",", "\n")
    results: list[str] = []
    for line in normalized.splitlines():
        token = line.strip(" -â€¢\t\r\n0123456789.")
        if not token:
            continue
        results.append(token.strip())
        if len(results) >= 3:
            break
    return results


ANSWER_EVAL_TEMPLATE = """You are grading a learner's answer with help from Gemini. Analyse carefully and respond with strict JSON (no code fences, no commentary).
Expected JSON schema:
{{
  "is_correct": true | false,
  "feedback": "<ì§§ì€ ì½”ë©˜íŠ¸ í•œêµ­ì–´>",
  "score": <0.0-1.0 ìˆ«ì>,
  "model_answer": "<ì •ë‹µ ë˜ëŠ” ëª¨ë²” ë‹µì•ˆ (í•œêµ­ì–´ ë˜ëŠ” í•„ìš”í•œ ê²½ìš° ì˜ì–´)>"
}}

- "feedback": ê°„ë‹¨í•˜ê³  ì‘ì›í•˜ëŠ” í•œêµ­ì–´ ë¬¸ì¥ 1~2ê°œ.
- "model_answer": í•™ìŠµìê°€ ì°¸ê³ í•  ì •ë‹µ ìš”ì•½. ì •ë‹µì´ ëª…í™•í•˜ì§€ ì•Šë‹¤ë©´ ì§ˆë¬¸ì„ ë” ë¶„ì„í•´ ì œê³µ ê°€ëŠ¥í•œ ìµœì„ ì˜ ë‹µì„ ì‘ì„±.
- "score": 0ê³¼ 1 ì‚¬ì´ (ì˜ˆ: 0.0, 0.25, 0.5, 0.75, 1.0).
- "is_correct": í•™ìŠµìì˜ ë‹µì´ ì¶©ë¶„íˆ ë§ë‹¤ë©´ true, ì•„ë‹ˆë©´ false.

ì§ˆë¬¸: {question}
í•™ìŠµì ë‹µë³€: {user_answer}
ì°¸ê³  ë¬¸ë§¥: {context}
"""


def _parse_json_response(raw_text: str) -> dict[str, object]:
    try:
        return json.loads(raw_text)
    except json.JSONDecodeError:
        start = raw_text.find("{")
        end = raw_text.rfind("}")
        if start != -1 and end != -1 and end > start:
            snippet = raw_text[start : end + 1]
            return json.loads(snippet)
        raise


@app.post("/api/hints", response_model=HintResponse)
async def generate_hint(payload: HintRequest):
    template = HINT_LEVEL_TEMPLATES.get(payload.level)
    if not template:
        raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒíŠ¸ ë ˆë²¨ì…ë‹ˆë‹¤.")

    context = payload.context.strip()
    if not context:
        raise HTTPException(status_code=400, detail="ë¬¸ë§¥(context)ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    prompt = template.format(context=context)

    try:
        model = genai.GenerativeModel(MODEL_CHAT, system_instruction=HINT_SYSTEM_PROMPT)
        ai_response = await model.generate_content_async(prompt)
        raw_text = "".join(
            part.text for part in ai_response.candidates[0].content.parts
        ).strip()

        hint_text = raw_text
        keywords: list[str] | None = None

        if payload.level == "keywords":
            keywords = _extract_keywords(raw_text)
            if keywords:
                hint_text = "\n".join(keywords)

        playful_remark = None
        if payload.usage_count >= 3:
            playful_remark = "ë‹¤ìŒì—” ìŠ¤ìŠ¤ë¡œ! ì´ë²ˆ íŒíŠ¸ë¡œ ê¼­ í’€ì–´ë´. ğŸ˜œ"

        return HintResponse(
            level=payload.level,
            hint_text=hint_text,
            keywords=keywords,
            playful_remark=playful_remark,
        )
    except Exception as error:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"íŒíŠ¸ ìƒì„± ì‹¤íŒ¨: {error}")


@app.post("/api/check-answer", response_model=AnswerCheckResponse)
async def check_answer(payload: AnswerCheckRequest):
    question = payload.question.strip()
    user_answer = payload.user_answer.strip()
    if not question:
        raise HTTPException(status_code=400, detail="ì±„ì í•  ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    if not user_answer:
        raise HTTPException(status_code=400, detail="í•™ìŠµì ë‹µë³€ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    context = payload.context.strip() if payload.context else ""
    prompt = ANSWER_EVAL_TEMPLATE.format(
        question=question,
        user_answer=user_answer,
        context=context or "ì—†ìŒ",
    )

    try:
        model = genai.GenerativeModel(MODEL_CHAT, system_instruction=EVAL_SYSTEM_PROMPT)
        ai_response = await model.generate_content_async(prompt)
        raw_text = "".join(
            part.text for part in ai_response.candidates[0].content.parts
        ).strip()
        try:
            result = _parse_json_response(raw_text)
        except Exception as parse_error:
            raise HTTPException(
                status_code=502,
                detail=f"ì±„ì  ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {parse_error}",
            )

        is_correct = bool(result.get("is_correct"))
        feedback = str(result.get("feedback") or "").strip()
        score_value = result.get("score")
        model_answer = result.get("model_answer")

        score_float: float | None = None
        if isinstance(score_value, (int, float)):
            score_float = max(0.0, min(1.0, float(score_value)))
        elif isinstance(score_value, str):
            try:
                parsed_score = float(score_value)
                score_float = max(0.0, min(1.0, parsed_score))
            except ValueError:
                score_float = None

        if not feedback:
            feedback = "ì±„ì  ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤."

        return AnswerCheckResponse(
            is_correct=is_correct,
            feedback=feedback,
            score=score_float,
            model_answer=str(model_answer).strip() if model_answer else None,
        )
    except HTTPException:
        raise
    except Exception as error:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ì±„ì  ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error}")


# --- ì„œë²„ ì‹¤í–‰ ---
def run(host: str = "0.0.0.0", port: int = 8000):
    import uvicorn
    print(f"Starting Voice Server on http://{host}:{port}")
    uvicorn.run(app, host=host, port=port, reload=True)

if __name__ == "__main__":
    run()
